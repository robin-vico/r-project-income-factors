---
title: "main"
author: "Robin VICO"
date: "2025-10-22"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    css: ["style.css"]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

# Step 1: Data Cleaning and Preparation

```{r, include=FALSE}
# Installer les packages si nécessaire
packages_needed <- c("tidyverse", "scales", "ggplot2", "dplyr", "knitr", "caret", "pROC","randomForest")
packages_to_install <- packages_needed[!(packages_needed %in% installed.packages()[,"Package"])]

if(length(packages_to_install) > 0) {
  install.packages(packages_to_install, repos = "https://cloud.r-project.org/")
}

library(tidyverse)
library(scales)
library(ggplot2)
library(dplyr)
library(knitr)
library(caret)
library(pROC)
```

```{r, include=FALSE}
raw_data = read.csv('data/raw/adult.csv')
kable(head(raw_data))
```

```{r, include=FALSE}
raw_data %>%
  dim() %>%
  print()
```

```{r, include=FALSE}
raw_data %>%
  colnames() %>%
  print()
```

```{r, include=FALSE}
raw_data %>%
  str() %>%
  print()
```

As we can see, there are some missing values in the dataset, set as '?'.

```{r}
NA_values = raw_data %>%
  filter(workclass=='?'| occupation=='?'| native.country=='?') %>%
  head() %>%
  kable()
```

```{r, include=FALSE}
print(dim(NA_values))
```

```{r, include=FALSE}
for (col_name in names(raw_data)) {
  cat("Colonne :", col_name, "\n")
  print(sort(unique(raw_data[[col_name]])))
  cat("\n")
}
```

First, we will clean the missing values of the workclass column.

```{r}
raw_data %>%
  count(workclass) %>%
  arrange(desc(n)) %>%
  mutate(percentage = n*100/32651) %>%
  kable()
```

We notice that the value 'private' is the most predominant.

To predict the real values of the missing values, we can try to go further by looking at the most common workclass for each sex.

```{r}
raw_data %>% 
  filter(workclass != '?', sex=='Male') %>% 
  count(workclass) %>%
  arrange(desc(n)) %>%
  kable()
```

```{r}
raw_data %>% 
  filter(workclass != '?', sex=='Female') %>% 
  count(workclass) %>%
  arrange(desc(n)) %>%
  kable()
```

Since it does not seem to have any pattern to determine what are the real values of the missing values, and because the 'Private' value is predominant (69% of the values), we will just replace all the missing values by the most common value.

```{r, include=FALSE}
most_common_workclasses = raw_data %>%
  count(workclass) %>%
  arrange(desc(n)) %>%
  mutate(percentage = n*100/32651)

most_common_workclass = most_common_workclasses$workclass[1]

cleaned_data = raw_data %>%
  mutate(workclass = recode(workclass, '?' = most_common_workclass))
head(cleaned_data)
```

```{r}
raw_data %>%
  count(occupation) %>%
  arrange(desc(n)) %>%
  mutate(percentage = n*100/32651) %>%
  kable()
```

Regarding the occupation column, we see that there are no occupation that dominate the others. That means that we cannot predict what are the values. So, replacing all the missing values by the most common one is the best idea.

We will simply drop the lines containing missing values for the occupation column.

```{r}
cleaned_data = cleaned_data %>%
  filter(occupation != '?')
```

For the missing values in the native.country column, we will replace them by the most common attribute, "United-States" since it is the majority of the elements.

```{r}
most_common_native_countries = raw_data %>%
  count(native.country) %>%
  arrange(desc(n)) %>%
  mutate(percentage = n*100/32651)

kable(head(most_common_native_countries))
```

```{r, include=FALSE}
most_common_native_country = most_common_native_countries$native.country[1]
print(most_common_native_country)
```

::: {style="overflow-x: auto;"}
```{r}
cleaned_data = cleaned_data %>%
  mutate(native.country = recode(native.country, '?' = most_common_native_country))
kable(head(cleaned_data))
```
:::

Summary : We replaced '?' values of workclass and native.country columns, by the most common values of both columns and we dropped the lines containing '?' values in the occupation column.

Now, because we have two look-alike variables, education and education.num, let's check if there's any redundancy.

```{r}
education_check <- cleaned_data %>%
    select(education, education.num)%>%
    distinct() %>%
    arrange(education.num)
kable(education_check)
```

After verification, we can confidently conclude that there is a perfect correlation and redundancy between the two variables. Therefore, it is not only acceptable but even preferable to exclude the education variable from our subsequent analysis.

Moreover, education is not the only variable that can be considered unnecessary. Based on our research, the fnlwgt (final weight) variable also does not contribute meaningfully to our predictive task. This variable represents the number of people in the surveyed population who share the same profile. Consequently, it does not help our models determine whether an individual is likely to earn more or less than \$50K per year.

```{r}
cleaned_data <- cleaned_data %>% 
  select(-fnlwgt, -education)
```

::: {style="overflow-x: auto;"}
```{r}
kable(head(cleaned_data))
```
:::

Categorical variables : Some categorical variables may contain leading or trailing whitespace.

As we see there is no column that contain any leading or trailing whitespace.

```{r}
library(dplyr)
library(stringr)

cols_with_whitespace <- cleaned_data %>%
  summarise(across(where(is.character), ~ any(str_detect(., "^\\s|\\s$"))))

kable(cols_with_whitespace)
```

As we see there is no column that contain any leading or trailing whitespace.

# Step 2: Feature Transformation and Engineering

## Grouping categories

Since "United-States" is the most common country and all the other values are negligible, we will just set "Other" to the countries that are not "United-States".

::: {style="overflow-x: auto;"}
```{r}
cleaned_data <- cleaned_data %>%
  mutate(native.country = ifelse(native.country == "United-States", "USA", "Other"))
  

kable(head(cleaned_data))
```
:::

## Target Transformation

::: {style="overflow-x: auto;"}
```{r}
cleaned_data = cleaned_data %>%
  mutate(income = ifelse(income == '>50K', 1, 0))

kable(head(cleaned_data))
```
:::

## Age Discretization

::: {style="overflow-x: auto;"}
```{r}
cleaned_data = cleaned_data %>%
  mutate(age.group = case_when(
    age >= 17 & age <= 20 ~ "Young",
    age >= 21 & age <= 59 ~ "Adult",
    age > 59 ~ "Senior",
  ))
kable(head(cleaned_data))
```
:::

## Analyzing Capital Gains/Losses

::: {style="overflow-x: auto;"}
```{r}
final_data = cleaned_data %>%
  mutate(net.capital = capital.gain - capital.loss) %>%
  select(-capital.gain, -capital.loss)

kable(head(final_data))
```
:::

# Step 3: Visualization and Exploration

## Income and Education Level

::: {style="overflow-x: auto;"}
```{r}
over_50k = final_data %>%
  filter(income == TRUE)
kable(head(over_50k))
```
:::

```{r}
ggplot(over_50k, aes(x = factor(education.num))) +
  geom_bar(aes(y = after_stat(count / sum(count)))) +
  scale_y_continuous(labels = scales::percent) +
  labs(
    title = "Proportion of individuals earning > 50K by education level",
    x = "Education number (education.num)",
    y = "Proportion of individuals in the > 50K subset"
  )
```

## Work Hours and Income

```{r}
data = final_data %>%
  mutate(income = factor(income, labels = c("<=50K", ">50K")))

ggplot(data, aes(x = hours.per.week, fill = income)) +
  geom_histogram(bins = 30) + 
  facet_wrap(~ income, scales = "free_y", ncol = 1) + 
  labs(
    title = "Distribution of hours per week, faceted by income class",
    x = "Hours per week",
    y = "Frequency (number of individuals)",
    fill = "Income class"
  )
```

## Impact of Marital Status

```{r}
sample_marital_status = data %>%
  select(marital.status, income)

ggplot(sample_marital_status, aes(x = marital.status, fill = income)) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = percent) +
  labs(
    title = "Impact of marital status on income",
    x = "Marital status",
    y = "Distribution of income class",
    fill = "Income class"
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

## Age distribution

```{r}
sample_age_distrib = data %>%
  select(age, income)

ggplot(sample_age_distrib, aes(x = age)) +
  geom_histogram(bins = 30, aes(fill = income), position = "identity") + 
  facet_wrap(~ income, scales = "free_y") + 
  labs(
    title = "Age distribution faceted by the income class",
    x = "Age",
    y = "Number of people",
    fill = "Income class"
  )
```

```{r}
ggplot(data, aes(x = relationship, fill = income)) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent) +
  labs(
    title = "Proportion of income > 50K by family role/relationship",
    x = "Relationship",
    y = "Proportion of income category",
    fill = "Income level"
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
ggplot(data, aes(x = marital.status, fill = income)) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent) +
  facet_wrap(~ sex) + 
  labs(
    title = "Proportion of income > 50K by marital status and sex",
    x = "Marital status",
    y = "Proportion of income category",
    fill = "Income level"
  ) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

```{r}
# Supposons que votre variable groupée s'appelle 'native.country.grouped'
ggplot(data, aes(x = native.country, fill = income)) +
  geom_bar(position = "fill") +
  scale_y_continuous(labels = scales::percent) +
  labs(
    title = "Proportion of high income by native country (US vs other)",
    x = "Native country (grouped)",
    y = "Proportion of income category",
    fill = "Income level"
  )
```

::: {style="overflow-x: auto;"}
```{r}
kable(head(final_data))
write.csv(final_data,"data/processed/clean_v1.csv")
```
:::

## Alternative Data Cleaning Approaches

Now that the data preparation is done as well as the visualisation, we can move on to the modeling but why test the model on only one type of cleaned data? That's the question we asked ourselves. Let's test other ways to clean the data so you can compare afterward.

Let's see what are the missing variables:

```{r}
df=raw_data
na_summary <- sapply(df, function(x) sum(x == "?" | is.na(x)))
na_percentage <- na_summary / nrow(df) * 100
na_df <- data.frame(variable = names(na_percentage), pourcentage_NA = na_percentage)
kable(na_df%>%filter(pourcentage_NA != 0))
```

The missing variables are occupation, workclass and native.country

```{r}

# Reusable function to plot categorical variable distribution with grouping of low-frequency categories
# - `col`: column name (quoted string) or unquoted symbol
# - `data`: data.frame containing the column
# - `max_categories`: number of top categories to keep (others grouped as 'Autres')
plot_categorical <- function(col, data, max_categories = 20) {
  # allow unquoted or quoted column name
  col_name <- if (is.character(col)) {
    col
  } else {
    deparse(substitute(col))
  }

  # validate data argument
  if (missing(data)) stop("`data` is missing; provide a data.frame as the second argument")
  if (is.function(data)) stop("`data` appears to be a function/closure; provide a data.frame named e.g. df")
  if (!is.data.frame(data)) stop("`data` must be a data.frame")

  if (!col_name %in% names(data)) stop(paste0("Column '", col_name, "' not found in data."))

  df_tmp <- data

  # ensure character and treat "?" as missing; keep NA label for plotting
  df_tmp[[col_name]] <- as.character(df_tmp[[col_name]])
  df_tmp[[col_name]][df_tmp[[col_name]] == "?"] <- NA_character_
  df_tmp[[col_name]][is.na(df_tmp[[col_name]])] <- "NA"

  # frequency table (including NA) and keep top categories
  counts_raw <- as.data.frame(table(df_tmp[[col_name]], useNA = "ifany"), stringsAsFactors = FALSE)
  colnames(counts_raw) <- c("valeur", "frequence")
  top_categories <- head(counts_raw[order(-counts_raw$frequence), "valeur"], max_categories)

  # group the rest into 'Autres'
  df_tmp[[col_name]] <- ifelse(df_tmp[[col_name]] %in% top_categories, df_tmp[[col_name]], "Autres")

  # recompute counts and percentages
  counts2 <- as.data.frame(table(df_tmp[[col_name]]), stringsAsFactors = FALSE)
  colnames(counts2) <- c("valeur", "frequence")
  counts2$pourcentage <- counts2$frequence / sum(counts2$frequence) * 100

  # order categories by percentage desc
  counts2$valeur <- factor(counts2$valeur, levels = counts2$valeur[order(-counts2$pourcentage)])

  # plot
  p <- ggplot(counts2, aes(x = valeur, y = pourcentage, fill = valeur)) +
    geom_col(show.legend = FALSE) +
    geom_text(aes(label = paste0(round(pourcentage, 1), "%")), vjust = -0.5, size = 3) +
    labs(title = paste("Répartition (pourcentage) de", col_name),
         x = col_name,
         y = "Pourcentage (%)") +
    theme_minimal() +
    theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
    ylim(0, max(counts2$pourcentage) * 1.12)

  print(p)
  invisible(counts2)
}
```

For the native.country, almost 90% of the population is from USA and the second single country is only at 2% so it makes sense to add to the mass the ? cases.

```{r}
plot_categorical("native.country",df,10)
```

```{r}
df <- df %>% mutate(native.country = ifelse(native.country == "?", "United-States", native.country))
```

For the workclass, the results are more complex. Even if there's the "private" category that contains more or less 70% of the total, there's still competitors around 6-7% by category. So it could be interesting to do a bit of profiling.

```{r}
plot_categorical("workclass",df)
```

Let's analyze the workclass missing values according to other variables. For Sex:

```{r}
df %>%
  filter(!is.na(workclass)) %>%
  group_by(sex, workclass) %>%
  summarise(count = n(), .groups = "drop") %>%
  group_by(sex) %>%
  mutate(percentage = count/sum(count)*100) %>%
  ggplot(aes(x = workclass, y = percentage, fill = sex)) +
    geom_bar(stat = "identity", position = "dodge") +
    labs(x = "Workclass", y = "Percentage", fill = "Sex") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

We can't really see a trend, the difference by workclass and by sex are not really significant.

Now for Age:

```{r}
df %>%
  filter(!is.na(workclass)) %>%
  mutate(age_group = cut(age, 
                         breaks = c(-Inf, 25, 35, 45, 55, 65, Inf),
                         labels = c("<25", "25-35", "35-45", "45-55", "55-65", "65+"))) %>%
  group_by(age_group, workclass) %>%
  summarise(count = n(), .groups = "drop") %>%
  group_by(age_group) %>%
  mutate(percentage = count/sum(count)*100) %>%
  ggplot(aes(x = workclass, y = percentage, fill = age_group)) +
    geom_bar(stat = "identity", position = "dodge") +
    labs(x = "Workclass", y = "Percentage", fill = "Age Group") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

We now know that an important portion of the missing workclass values are from old people (65+). More generally we see that age is strongly related to the workclass. The older you are, the less chance you have to be in "Private" workclass (80% for <25 vs 40% for 65+). With this degree of correlation, the age parameter is a good candidate to help us fill the missing workclass values. Let's search for more.

For the education.num parameter:

```{r}
df %>%
  filter(!is.na(workclass)) %>%
  group_by(education.num, workclass) %>%
  summarise(count = n(), .groups = "drop") %>%
  group_by(education.num) %>%
  mutate(percentage = count/sum(count)*100) %>%
  ggplot(aes(x = workclass, y = percentage, fill = as.factor(education.num))) +
    geom_bar(stat = "identity", position = "dodge") +
    labs(x = "Workclass", y = "Percentage", fill = "Education Num") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

From this graph we can conclude several things: 
1. In terms of level of study, the missing class behaves pretty similarly to the private class which makes sense considering that the private class is the majority of the workclass. 
2. The highly educated (14+) behaves quite differently making a huge part of these class: Local and state governments & self employed.

Let's keep digging for clues.

For marital status:

```{r}
df %>%
  filter(!is.na(workclass)) %>%
  group_by(marital.status, workclass) %>%
  summarise(count = n(), .groups = "drop") %>%
  group_by(marital.status) %>%
  mutate(percentage = count/sum(count)*100) %>%
  ggplot(aes(x = workclass, y = percentage, fill = as.factor(marital.status))) +
    geom_bar(stat = "identity", position = "dodge") +
    labs(x = "Workclass", y = "Percentage", fill = "Marital Status") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Seeing the graph, it seems the marital status doesn't really influence the workclass.

For hours per week:

```{r}
df %>%
  filter(!is.na(workclass)) %>%
  mutate(hpweek_group = cut(hours.per.week, 
                         breaks = c(-Inf, 10, 20, 30, 40, 50, 60 ,70, 80,90, Inf),
                         labels = c("<10", "10-20", "20-30", "30-40", "40-50", "50-60", "60-70" ,"70-80", "80-90", "90+"))) %>%
  group_by(hpweek_group, workclass) %>%
  summarise(count = n(), .groups = "drop") %>%
  group_by(hpweek_group) %>%
  mutate(percentage = count/sum(count)*100) %>%
  ggplot(aes(x = workclass, y = percentage, fill = hpweek_group)) +
    geom_bar(stat = "identity", position = "dodge") +
    labs(x = "Workclass", y = "Percentage", fill = "hours per week Group") +
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

Here we have a much more influenced graph. If we compare it to the workclass histogram we can see some obvious disparities such as: the high percentage of people working little (<10) in the missing class and the high percentage working a lot (80+) in the self-employed not incorporated class. These spikes deform the habitual chunk of the private class, showing real influence from the hours per week parameter.

To conclude on the workclass: it can be useful to fill the missing workclass to first profile each of its representatives by age and hours per week. To do so, we first need to modify the dataset to turn the age and the hours.per.week into discrete variables by grouping them.

```{r}
df_modified <- df %>%
  mutate(age_group = cut(age, 
                         breaks = c(-Inf, 25, 35, 45, 55, 65, Inf),
                         labels = c("<25", "25-35", "35-45", "45-55", "55-65", "65+"))) %>%
  mutate(hpweek_group = cut(hours.per.week, 
                         breaks = c(-Inf, 10, 20, 30, 40, 50, 60 ,70, 80,90, Inf),
                         labels = c("<10", "10-20", "20-30", "30-40", "40-50", "50-60", "60-70" ,"70-80", "80-90", "90+")))
```

At this step of the process, the goal is to gather some data on what are the dominant (higher frequency) workclass in each couple of age class and hour per week class.

```{r}
dominant_workclass <- df_modified %>%
  filter(workclass!="?") %>%
  group_by(workclass, age_group, hpweek_group) %>%
  summarise(count = n(), .groups = "drop") %>%
  group_by(age_group, hpweek_group) %>%
  mutate(percentage = count / sum(count) * 100) %>%
  slice_max(order_by = percentage, n = 1, with_ties = FALSE) %>%
  ungroup()

kable(head(dominant_workclass))
```

Now we can use this profile to fill the missing workclass values according to the age_group and hpweek_group of each missing case.

```{r}
fill_workclass <- function(age_grp, hpweek_grp) {
  profile_workclass <- dominant_workclass %>%
    filter(age_group == age_grp, hpweek_group == hpweek_grp) %>%
    pull(workclass)
  
  return(ifelse(length(profile_workclass)==0,"Private",profile_workclass))
}

df_filled <- df_modified %>%
  rowwise() %>%
  mutate(workclass = ifelse(workclass == "?",
                            fill_workclass(age_group, hpweek_group),
                            workclass)) %>%
  ungroup()
```

After having successfully addressed the workclass issue, we now need to do the same for the "occupation" variable that's way more spread across its different classes as we can see on the graph below.

```{r}
plot_categorical("occupation",df)
```

Let's test how the other variables can influence the occupation. Precision: we're now using a different function to graph the data because it was becoming difficult to see the influence between variables. We now graph the difference between the actual repartition of marital status over each occupation and the theoretical repartition if there was total independence between the two variables: occupation and marital status.

```{r}
real_dist <- df %>%
  filter(!is.na(occupation)) %>%
  group_by(marital.status, occupation) %>%
  summarise(count = n(), .groups = "drop") %>%
  group_by(marital.status) %>%
  mutate(percentage = count/sum(count)*100)

reference_dist <- df %>%
  filter(!is.na(occupation)) %>%
  group_by(occupation) %>%
  summarise(count = n(), .groups = "drop") %>%
  mutate(percentage_ref = count/sum(count)*100)

diff_data <- real_dist %>%
  left_join(reference_dist %>% select(occupation, percentage_ref), 
            by = "occupation") %>%
  mutate(diff = percentage - percentage_ref)

ggplot(diff_data, aes(x = occupation, y = diff, fill = marital.status)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  labs(x = "Occupation", 
       y = "Difference (% reel - % theorical)", 
       fill = "Marital Status",
       title = "Distance from the variables Independence") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

mean_diff_marital_status <- diff_data %>%
  group_by(marital.status) %>%
  summarise(ecart_moyen = mean(abs(diff))) %>%
  arrange(desc(ecart_moyen))
```

Let's check for age (discretized):

```{r}
df_test <- df_modified

real_dist <- df_test %>%
  filter(!is.na(occupation)) %>%
  group_by(age_group, occupation) %>%
  summarise(count = n(), .groups = "drop") %>%
  group_by(age_group) %>%
  mutate(percentage = count/sum(count)*100)

reference_dist <- df_test %>%
  filter(!is.na(occupation)) %>%
  group_by(occupation) %>%
  summarise(count = n(), .groups = "drop") %>%
  mutate(percentage_ref = count/sum(count)*100)

diff_data <- real_dist %>%
  left_join(reference_dist %>% select(occupation, percentage_ref), 
            by = "occupation") %>%
  mutate(diff = percentage - percentage_ref)

ggplot(diff_data, aes(x = occupation, y = diff, fill = age_group)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  labs(x = "Occupation", 
       y = "Difference (% reel - % theorical)", 
       fill = "age group",
       title = "Distance from the variables Independence") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

mean_diff_age_group <- diff_data %>%
  group_by(age_group) %>%
  summarise(ecart_moyen = mean(abs(diff))) %>%
  arrange(desc(ecart_moyen))
```

Checking correlation with relationship:

```{r}
real_dist <- df %>%
  filter(!is.na(occupation)) %>%
  group_by(relationship, occupation) %>%
  summarise(count = n(), .groups = "drop") %>%
  group_by(relationship) %>%
  mutate(percentage = count/sum(count)*100)

reference_dist <- df %>%
  filter(!is.na(occupation)) %>%
  group_by(occupation) %>%
  summarise(count = n(), .groups = "drop") %>%
  mutate(percentage_ref = count/sum(count)*100)

diff_data <- real_dist %>%
  left_join(reference_dist %>% select(occupation, percentage_ref), 
            by = "occupation") %>%
  mutate(diff = percentage - percentage_ref)

ggplot(diff_data, aes(x = occupation, y = diff, fill = relationship)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  labs(x = "Occupation", 
       y = "Difference (% reel - % theorical)", 
       fill = "relationship",
       title = "Distance from the variables Independence") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

We can see that the relationship variable outweighs by far the age in regards to influencing the occupation variable.

To satisfy our curiosity, let's test one last variable: sex.

```{r}
real_dist <- df %>%
  filter(!is.na(occupation)) %>%
  group_by(sex, occupation) %>%
  summarise(count = n(), .groups = "drop") %>%
  group_by(sex) %>%
  mutate(percentage = count/sum(count)*100)

reference_dist <- df %>%
  filter(!is.na(occupation)) %>%
  group_by(occupation) %>%
  summarise(count = n(), .groups = "drop") %>%
  mutate(percentage_ref = count/sum(count)*100)

diff_data <- real_dist %>%
  left_join(reference_dist %>% select(occupation, percentage_ref), 
            by = "occupation") %>%
  mutate(diff = percentage - percentage_ref)

ggplot(diff_data, aes(x = occupation, y = diff, fill = sex)) +
  geom_bar(stat = "identity", position = "dodge") +
  geom_hline(yintercept = 0, linetype = "dashed", color = "black") +
  labs(x = "Occupation", 
       y = "Difference (% reel - % theorical)", 
       fill = "sex",
       title = "Distance from the variables Independence") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

mean_diff_sex <- diff_data %>%
  group_by(sex) %>%
  summarise(ecart_moyen = mean(abs(diff))) %>%
  arrange(desc(ecart_moyen))
```

So the sex does have an important role on occupation! Which variables do we choose now to profile our occupation-missing subjects?

To be sure, let's measure the average distance from decorrelation (or Independence) for these last 3 variables:
```{r}
summary_table <- data.frame(
  variable = c("marital.status", "age.group", "sex"),
  mean_diff = c(
    mean(mean_diff_marital_status$ecart_moyen, na.rm = TRUE),
    mean(mean_diff_age_group$ecart_moyen,     na.rm = TRUE),
    mean(mean_diff_sex$ecart_moyen,           na.rm = TRUE)
  )
)
summary_table$mean_diff <- paste0(round(summary_table$mean_diff, 2), " %")

kable(summary_table, col.names = c("", "Mean diff"))
```
 


It appears that the 2 most correlated variables of the 3 are marital status and sex, so let's profile by that. To do that we need to find what's the most frequent occupation for each couple of (marital status, sex).

```{r}
dominant_occupation <- raw_data %>%
  filter(occupation!="?") %>%
  group_by(occupation, marital.status, sex) %>%
  summarise(count = n(), .groups = "drop") %>%
  group_by(marital.status, sex) %>%
  mutate(percentage = count / sum(count) * 100) %>%
  slice_max(order_by = percentage, n = 1, with_ties = FALSE) %>%
  ungroup()

kable(head(dominant_occupation))
```

Now let's create a function to fill the missing occupation values:

```{r}
fill_occupation <- function(marital_status, Sex) {
  profile_occupation <- dominant_occupation %>%
    filter(marital.status == marital_status, sex == Sex) %>%
    pull(occupation)
  
  return(profile_occupation)
}

df_fully_filled <- df_filled %>%
  rowwise() %>%
  mutate(occupation = ifelse(occupation == "?", fill_occupation(marital.status, sex), occupation)) %>%
  ungroup()
```

::: {style="overflow-x: auto;"}
```{r}
kable(head(df_fully_filled))
```
:::


### Check for remaining "?" and NA values and display a tidy summary for knitting
```{r}

library(tibble)

remaining_q <- sapply(df_fully_filled, function(x) {
  if (is.factor(x) || is.character(x)) sum(as.character(x) == "?", na.rm = TRUE) else 0
})
remaining_na <- sapply(df_fully_filled, function(x) sum(is.na(x)))

remaining <- tibble(
  variable = names(remaining_q),
  count_q = as.integer(remaining_q),
  count_na = as.integer(remaining_na),
  total_rows = nrow(df_fully_filled)
) %>%
  mutate(pct_q = round(count_q / total_rows * 100, 2)) %>%
  arrange(desc(count_q), desc(count_na))

if (all(remaining$count_q == 0 & remaining$count_na == 0)) {
  cat("No remaining '?' or NA values in df_fully_filled.\n")
} else {
  knitr::kable(
    remaining,
    col.names = c("Variable", "Count '?'", "Count NA", "Total rows", "% rows with '?'"),
    digits = 2,
    caption = "Remaining '?' and NA values by column"
  )
}
```

```{r}
write.csv(df_fully_filled,"data/processed/clean_v2.csv")
```

# Step 4: Modeling and Prediction (Data Science)

## Preparing Data for Modeling

```{r, include=FALSE}
data_for_model <- read.csv('data/processed/clean_v1.csv') %>% 
  mutate(income = factor(income, labels = c("L50K", "G50K"))) %>%
  select(-X)

categorical_vars <- names(data_for_model)[
  (sapply(data_for_model, is.factor) | sapply(data_for_model, is.character)) & 
  names(data_for_model) != "income"
]

if (length(categorical_vars) == 0) {
  stop("Errorr: No categorical variable was found.")
}

formula_vars <- paste(categorical_vars, collapse = " + ")

dummies <- dummyVars(paste("~", formula_vars), data = data_for_model)

encoded_data <- as.data.frame(predict(dummies, newdata = data_for_model))

final_data_encoded <- bind_cols(
  data_for_model %>% select_if(is.numeric),
  encoded_data,
  income = data_for_model$income
)

set.seed(42)
train_index <- createDataPartition(final_data_encoded$income, p = 0.7, list = FALSE)

training_set <- final_data_encoded[train_index, ]
testing_set <- final_data_encoded[-train_index, ]
```

## Training of the models

### Logistic Regression

```{r, eval = FALSE}
logistic_model <- glm(income ~ ., 
                      data = training_set, 
                      family = "binomial")

print("Logistic regression model training success.")

dir.create("models", showWarnings = FALSE)
saveRDS(logistic_model, file = "models/logistic_model.rds")
```

```{r}
logistic_model_loaded = readRDS("models/logistic_model.rds")
```

### Random Forest

```{r, eval=FALSE}
library(randomForest)

fit_control <- trainControl(method = "cv", # Validation croisée
                            number = 5,   # 5 plis
                            classProbs = TRUE, # Nécessaire pour l'AUC
                            summaryFunction = twoClassSummary,
                            verboseIter = TRUE)

rf_model <- train(income ~ ., 
                  data = training_set, 
                  method = "rf", 
                  trControl = fit_control,
                  metric = "ROC") # Optimiser sur l'AUC (ROC)

dir.create("models", showWarnings = FALSE)
saveRDS(rf_model, file = "models/rf_model.rds")
```

```{r}
rf_model_loaded = readRDS(file = "models/rf_model.rds")
```

## Evaluation and Interpretation

```{r, include=FALSE}
lr_predictions <- predict(logistic_model_loaded, testing_set, type = "response")
lr_predicted_class <- factor(ifelse(lr_predictions > 0.5, "G50K", "L50K"), levels = c("L50K", "G50K"))

rf_predictions <- predict(rf_model_loaded, testing_set)
rf_probs <- predict(rf_model_loaded, testing_set, type = "prob")

lr_conf_matrix <- confusionMatrix(lr_predicted_class, testing_set$income)
lr_auc <- roc(testing_set$income, lr_predictions, levels = c("L50K", "G50K"))

rf_conf_matrix <- confusionMatrix(rf_predictions, testing_set$income)
rf_auc <- roc(testing_set$income, rf_probs$G50K, levels = c("L50K", "G50K"))
```

### Confusion Matrix and AUC Score

#### Logistic Regression Results

```{r, echo=FALSE}
lr_results <- data.frame(
  Metric = c("Accuracy", "Sensitivity", "Specificity", "AUC"),
  Value = c(
    paste0(round(lr_conf_matrix$overall["Accuracy"] * 100, 2), "%"),
    paste0(round(lr_conf_matrix$byClass["Sensitivity"] * 100, 2), "%"),
    paste0(round(lr_conf_matrix$byClass["Specificity"] * 100, 2), "%"),
    round(lr_auc$auc, 4)
  )
)
kable(lr_results, caption = "Logistic Regression Performance Metrics")
```

**Confusion Matrix:**
```{r, echo=FALSE}
lr_cm_table <- as.data.frame.matrix(lr_conf_matrix$table)
kable(lr_cm_table, caption = "Logistic Regression - Confusion Matrix")
```

#### Random Forest Results

```{r, echo=FALSE}
rf_results <- data.frame(
  Metric = c("Accuracy", "Sensitivity", "Specificity", "AUC"),
  Value = c(
    paste0(round(rf_conf_matrix$overall["Accuracy"] * 100, 2), "%"),
    paste0(round(rf_conf_matrix$byClass["Sensitivity"] * 100, 2), "%"),
    paste0(round(rf_conf_matrix$byClass["Specificity"] * 100, 2), "%"),
    round(rf_auc$auc, 4)
  )
)
kable(rf_results, caption = "Random Forest Performance Metrics")
```

**Confusion Matrix:**
```{r, echo=FALSE}
rf_cm_table <- as.data.frame.matrix(rf_conf_matrix$table)
kable(rf_cm_table, caption = "Random Forest - Confusion Matrix")
```

### Feature Importance

```{r, echo=FALSE}
rf_importance <- varImp(rf_model_loaded, scale = FALSE)

top_5_features <- head(
  rf_importance$importance[order(-rf_importance$importance$Overall), , drop = FALSE], 
  5
)

top_5_df <- data.frame(
  Feature = rownames(top_5_features),
  Importance = top_5_features$Overall
)

kable(top_5_df, 
      row.names = FALSE,
      col.names = c("Feature", "Importance Score"),
      caption = "Top 5 Most Important Variables (Random Forest)",
      digits = 2)
```

# Step 5: Modeling with Alternative Data Cleaning (v2)

Now let's train and evaluate the same models using the alternative data cleaning approach (clean_v2.csv) where we used profiling to fill missing values more intelligently.

## Preparing Data for Modeling (v2)

```{r, include=FALSE}
data_for_model_v2 <- read.csv('data/processed/clean_v2.csv') %>% 
  mutate(income = ifelse(income == '>50K', 1, 0)) %>%
  mutate(income = factor(income, labels = c("L50K", "G50K"))) %>%
  select(-X)

# Remove the temporary grouping columns if they exist
if ("age_group" %in% names(data_for_model_v2)) {
  data_for_model_v2 <- data_for_model_v2 %>% select(-age_group)
}
if ("hpweek_group" %in% names(data_for_model_v2)) {
  data_for_model_v2 <- data_for_model_v2 %>% select(-hpweek_group)
}

categorical_vars_v2 <- names(data_for_model_v2)[
  (sapply(data_for_model_v2, is.factor) | sapply(data_for_model_v2, is.character)) & 
  names(data_for_model_v2) != "income"
]

if (length(categorical_vars_v2) == 0) {
  stop("Error: No categorical variable was found.")
}

formula_vars_v2 <- paste(categorical_vars_v2, collapse = " + ")

dummies_v2 <- dummyVars(paste("~", formula_vars_v2), data = data_for_model_v2)

encoded_data_v2 <- as.data.frame(predict(dummies_v2, newdata = data_for_model_v2))

final_data_encoded_v2 <- bind_cols(
  data_for_model_v2 %>% select_if(is.numeric),
  encoded_data_v2,
  income = data_for_model_v2$income
)

set.seed(42)
train_index_v2 <- createDataPartition(final_data_encoded_v2$income, p = 0.7, list = FALSE)

training_set_v2 <- final_data_encoded_v2[train_index_v2, ]
testing_set_v2 <- final_data_encoded_v2[-train_index_v2, ]
```

## Training of the models (v2)

### Logistic Regression (v2)

```{r, eval=FALSE}
# Check if model exists, if not train it
if (!file.exists("models/logistic_model_v2.rds")) {
  logistic_model_v2 <- glm(income ~ ., 
                        data = training_set_v2, 
                        family = "binomial")
  
  print("Logistic regression model v2 training success.")
  
  dir.create("models", showWarnings = FALSE)
  saveRDS(logistic_model_v2, file = "models/logistic_model_v2.rds")
}
```

```{r, include=FALSE}
logistic_model_v2_loaded = readRDS("models/logistic_model_v2.rds")
```

### Random Forest (v2)

```{r, eval=FALSE}
# Check if model exists, if not train it
if (!file.exists("models/rf_model_v2.rds")) {
  library(randomForest)
  
  fit_control_v2 <- trainControl(method = "cv",
                              number = 5,
                              classProbs = TRUE,
                              summaryFunction = twoClassSummary,
                              verboseIter = TRUE)
  
  rf_model_v2 <- train(income ~ ., 
                    data = training_set_v2, 
                    method = "rf", 
                    trControl = fit_control_v2,
                    metric = "ROC")
  
  dir.create("models", showWarnings = FALSE)
  saveRDS(rf_model_v2, file = "models/rf_model_v2.rds")
}
```

```{r, include=FALSE}
rf_model_v2_loaded = readRDS(file = "models/rf_model_v2.rds")
```

## Evaluation and Interpretation (v2)

```{r, include=FALSE}
lr_predictions_v2 <- predict(logistic_model_v2_loaded, testing_set_v2, type = "response")
lr_predicted_class_v2 <- factor(ifelse(lr_predictions_v2 > 0.5, "G50K", "L50K"), levels = c("L50K", "G50K"))

rf_predictions_v2 <- predict(rf_model_v2_loaded, testing_set_v2)
rf_probs_v2 <- predict(rf_model_v2_loaded, testing_set_v2, type = "prob")

lr_conf_matrix_v2 <- confusionMatrix(lr_predicted_class_v2, testing_set_v2$income)
lr_auc_v2 <- roc(testing_set_v2$income, lr_predictions_v2, levels = c("L50K", "G50K"))

rf_conf_matrix_v2 <- confusionMatrix(rf_predictions_v2, testing_set_v2$income)
rf_auc_v2 <- roc(testing_set_v2$income, rf_probs_v2$G50K, levels = c("L50K", "G50K"))
```

### Confusion Matrix and AUC Score (v2)

#### Logistic Regression Results (v2)

```{r, echo=FALSE}
lr_results_v2 <- data.frame(
  Metric = c("Accuracy", "Sensitivity", "Specificity", "AUC"),
  Value = c(
    paste0(round(lr_conf_matrix_v2$overall["Accuracy"] * 100, 2), "%"),
    paste0(round(lr_conf_matrix_v2$byClass["Sensitivity"] * 100, 2), "%"),
    paste0(round(lr_conf_matrix_v2$byClass["Specificity"] * 100, 2), "%"),
    round(lr_auc_v2$auc, 4)
  )
)
kable(lr_results_v2, caption = "Logistic Regression (v2) Performance Metrics")
```

**Confusion Matrix:**
```{r, echo=FALSE}
lr_cm_table_v2 <- as.data.frame.matrix(lr_conf_matrix_v2$table)
kable(lr_cm_table_v2, caption = "Logistic Regression (v2) - Confusion Matrix")
```

#### Random Forest Results (v2)

```{r, echo=FALSE}
rf_results_v2 <- data.frame(
  Metric = c("Accuracy", "Sensitivity", "Specificity", "AUC"),
  Value = c(
    paste0(round(rf_conf_matrix_v2$overall["Accuracy"] * 100, 2), "%"),
    paste0(round(rf_conf_matrix_v2$byClass["Sensitivity"] * 100, 2), "%"),
    paste0(round(rf_conf_matrix_v2$byClass["Specificity"] * 100, 2), "%"),
    round(rf_auc_v2$auc, 4)
  )
)
kable(rf_results_v2, caption = "Random Forest (v2) Performance Metrics")
```

**Confusion Matrix:**
```{r, echo=FALSE}
rf_cm_table_v2 <- as.data.frame.matrix(rf_conf_matrix_v2$table)
kable(rf_cm_table_v2, caption = "Random Forest (v2) - Confusion Matrix")
```

### Feature Importance (v2)

```{r, echo=FALSE}
rf_importance_v2 <- varImp(rf_model_v2_loaded, scale = FALSE)

top_5_features_v2 <- head(
  rf_importance_v2$importance[order(-rf_importance_v2$importance$Overall), , drop = FALSE], 
  5
)

top_5_df_v2 <- data.frame(
  Feature = rownames(top_5_features_v2),
  Importance = top_5_features_v2$Overall
)

kable(top_5_df_v2, 
      row.names = FALSE,
      col.names = c("Feature", "Importance Score"),
      caption = "Top 5 Most Important Variables (Random Forest v2)",
      digits = 2)
```

# Step 6: Comparison of Results

Now let's compare the performance of models trained on both data cleaning approaches:

## Performance Comparison Table

```{r, echo=FALSE}
comparison_table <- data.frame(
  Model = c("Logistic Regression (v1)", "Random Forest (v1)", 
            "Logistic Regression (v2)", "Random Forest (v2)"),
  Accuracy = c(
    lr_conf_matrix$overall["Accuracy"],
    rf_conf_matrix$overall["Accuracy"],
    lr_conf_matrix_v2$overall["Accuracy"],
    rf_conf_matrix_v2$overall["Accuracy"]
  ),
  AUC = c(
    lr_auc$auc,
    rf_auc$auc,
    lr_auc_v2$auc,
    rf_auc_v2$auc
  ),
  Sensitivity = c(
    lr_conf_matrix$byClass["Sensitivity"],
    rf_conf_matrix$byClass["Sensitivity"],
    lr_conf_matrix_v2$byClass["Sensitivity"],
    rf_conf_matrix_v2$byClass["Sensitivity"]
  ),
  Specificity = c(
    lr_conf_matrix$byClass["Specificity"],
    rf_conf_matrix$byClass["Specificity"],
    lr_conf_matrix_v2$byClass["Specificity"],
    rf_conf_matrix_v2$byClass["Specificity"]
  )
)

comparison_table$Accuracy <- paste0(round(comparison_table$Accuracy * 100, 2), "%")
comparison_table$AUC <- round(as.numeric(comparison_table$AUC), 4)
comparison_table$Sensitivity <- paste0(round(comparison_table$Sensitivity * 100, 2), "%")
comparison_table$Specificity <- paste0(round(comparison_table$Specificity * 100, 2), "%")

kable(comparison_table, 
      col.names = c("Model", "Accuracy", "AUC", "Sensitivity", "Specificity"),
      caption = "Model Performance Comparison: Simple vs Profiling-based Data Cleaning",
      align = c("l", "c", "c", "c", "c"))
```

## Key Findings

### Data Cleaning Approaches Summary

**Approach v1 (Simple):**

- Replaced workclass missing values with most common value (Private)
- Dropped rows with missing occupation values
- Replaced native.country missing values with most common value (United-States)

**Approach v2 (Profiling-based):**

- Filled workclass based on age group and hours per week profiling
- Filled occupation based on marital status and sex profiling
- Replaced native.country missing values with United-States

### Model Performance Analysis

```{r, echo=FALSE, results='asis'}
best_model_v1 <- ifelse(rf_auc$auc > lr_auc$auc, "Random Forest", "Logistic Regression")
best_model_v2 <- ifelse(rf_auc_v2$auc > lr_auc_v2$auc, "Random Forest", "Logistic Regression")

best_auc_v1 <- max(rf_auc$auc, lr_auc$auc)
best_auc_v2 <- max(rf_auc_v2$auc, lr_auc_v2$auc)

cat("**Best performing model with v1 data:**", best_model_v1, 
    "(AUC =", round(best_auc_v1, 4), ")\n\n")
cat("**Best performing model with v2 data:**", best_model_v2, 
    "(AUC =", round(best_auc_v2, 4), ")\n\n")

difference <- abs(best_auc_v2 - best_auc_v1)
percentage_diff <- round(difference * 100, 2)

cat("### Conclusion\n\n")
cat("The difference in model performance between the two data cleaning approaches is minimal, with only a", 
    percentage_diff, "% difference in AUC score.\n\n")

cat("**Key Insights:**\n\n")
cat("- Both the simple approach (v1) and the profiling-based approach (v2) yield nearly identical results\n")
cat("- The sophisticated missing value imputation based on demographic patterns does not significantly improve model accuracy\n")
cat("- The information loss from the simpler approach (dropping rows and using mode imputation) appears to be negligible\n\n")

cat("**Practical Recommendation:**\n\n")
cat("Given the marginal performance difference, **the simple approach (v1) is preferable** for this dataset because:\n\n")
cat("1. **Computational efficiency**: Significantly faster data preparation and model training\n")
cat("2. **Simplicity**: Easier to implement and maintain in production environments\n")
cat("3. **Cost-benefit**: The minimal information loss does not justify the additional computational complexity\n\n")

cat("This analysis demonstrates that, for this particular income prediction task, sophisticated data cleaning techniques do not provide substantial benefits over simpler approaches, making the trade-off in favor of computational efficiency worthwhile.\n")
```
