---
title: "prediction"
author: "Robin VICO"
date: "2025-11-10"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Step 4: Modeling and Prediction (Data Science)

Preparing Data for Modeling: Convert all remaining categorical variables into "dummy" variables (one-hot encoding) so they can be used by the models.

```{r}
library(caret)
data_for_model <- final_data %>% 
  select(-fnlwgt, -education) %>%
  mutate(income = factor(income, labels = c("L50K", "G50K"))) 

categorical_vars <- names(data_for_model)[
  (sapply(data_for_model, is.factor) | sapply(data_for_model, is.character)) & 
  names(data_for_model) != "income"
]

if (length(categorical_vars) == 0) {
  stop("Erreur: Aucune variable catégorielle (factor ou character) n'a été trouvée pour l'encodage à chaud.")
}

formula_vars <- paste(categorical_vars, collapse = " + ")

dummies <- dummyVars(paste("~", formula_vars), data = data_for_model)

encoded_data <- data.frame(predict(dummies, newdata = data_for_model))

final_data_encoded <- bind_cols(
  data_for_model %>% select_if(is.numeric),
  encoded_data,
  income = data_for_model$income
)

set.seed(42)
train_index <- createDataPartition(final_data_encoded$income, p = 0.7, list = FALSE)

training_set <- final_data_encoded[train_index, ]
testing_set <- final_data_encoded[-train_index, ]
```

training if the models :

```{r}
logistic_model <- glm(income ~ ., 
                      data = training_set, 
                      family = "binomial")

print("Logistic regression model training success.")
```

```{r}
library(randomForest)

fit_control <- trainControl(method = "cv", # Validation croisée
                            number = 5,   # 5 plis
                            classProbs = TRUE, # Nécessaire pour l'AUC
                            summaryFunction = twoClassSummary,
                            verboseIter = TRUE)

rf_model <- train(income ~ ., 
                  data = training_set, 
                  method = "rf", 
                  trControl = fit_control,
                  metric = "ROC") # Optimiser sur l'AUC (ROC)

print("Random forest model training success.")
```

predictions :

```{r}
# ----------------- Prédictions -----------------

# Régression Logistique : Classe prédite
lr_predictions <- predict(logistic_model, testing_set, type = "response")
lr_predicted_class <- factor(ifelse(lr_predictions > 0.5, "G50K", "L50K"), levels = c("L50K", "G50K"))

# Forêt Aléatoire : Classe prédite
rf_predictions <- predict(rf_model, testing_set)

# Forêt Aléatoire : Probabilités (nécessaires pour l'AUC)
rf_probs <- predict(rf_model, testing_set, type = "prob")
```

```{r}
library(pROC)

lr_predictions <- predict(logistic_model, testing_set, type = "response")

lr_predicted_class <- factor(ifelse(lr_predictions > 0.5, "G50K", "L50K"), 
                             levels = c("L50K", "G50K"))
lr_conf_matrix <- confusionMatrix(lr_predicted_class, testing_set$income)

print(lr_conf_matrix)

lr_conf_matrix <- confusionMatrix(lr_predicted_class, testing_set$income)
lr_auc <- roc(testing_set$income, lr_predictions, levels = c("L50K", "G50K"))

print("--- Évaluation Régression Logistique ---")
print(lr_conf_matrix)
cat("AUC Score:", lr_auc$auc, "\n\n")


rf_conf_matrix <- confusionMatrix(rf_predictions, testing_set$income)
rf_auc <- roc(testing_set$income, rf_probs$G50K, levels = c("L50K", "G50K"))

print("--- Évaluation Forêt Aléatoire ---")
print(rf_conf_matrix)
cat("AUC Score:", rf_auc$auc, "\n\n")
```

```{r}
# ----------------- Importance des Variables (Forêt Aléatoire) -----------------

# Calculer l'importance des variables
rf_importance <- varImp(rf_model, scale = FALSE)

# Extraire les 5 premières variables les plus importantes
top_5_features <- head(
  rf_importance$importance[order(-rf_importance$importance$Overall), , drop = FALSE], 
  5
)

print("--- Top 5 des Facteurs Prédictifs (Forêt Aléatoire) ---")
print(top_5_features)
```
